{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4b38df5f-3f37-41af-9ca4-9281c59382ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# paramter cell do not remove!!\n",
    "nb_parm='datalake|raw/pdf|Birddiversityanddistribution|pdf||300|150'\n",
    "# nb_parm='datalake|raw/text-csv|PFW_spp_translation_table_May2024|csv||300|150'\n",
    "# nb_parm='datalake|raw/text-csv|BRID_data|txt||300|150'\n",
    "embed_model = \"mxbai-embed-large\" \n",
    "gen_model = \"deepseek-r1:7b\" #\"command-r\"\n",
    "collection = \"Bridknowledge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bf819a96-44a2-4ff8-855e-7a7aab695c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"/home/jovyan/notebooks\")\n",
    "from Framework.module import Utility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6bb212-b8b8-4a0e-ab65-5e08e3226e49",
   "metadata": {},
   "source": [
    "## Do the task After this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "357bb00d-abbb-49b6-9688-2e5c2d7f371c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket_name: datalake\n",
      "path_to_file: raw/text-csv\n",
      "file_name: BRID_data.txt\n",
      "file_type: txt\n",
      "dlm: \n",
      "chunk_size: 300\n",
      "overlap: 150\n",
      "embed_model: mxbai-embed-large\n",
      "gen_model: deepseek-r1:7b\n",
      "collection: Bridknowledge\n"
     ]
    }
   ],
   "source": [
    "bucket_name, path_to_file, file_name, file_type, dlm, chunk_size, overlap = nb_parm.split('|')\n",
    "######PREPROCESSING###################\n",
    "file_name = file_name + '.' + file_type\n",
    "chunk_size = int(chunk_size)\n",
    "overlap = int(overlap)\n",
    "######################################\n",
    "print(\"bucket_name:\", bucket_name)\n",
    "print(\"path_to_file:\", path_to_file)\n",
    "print(\"file_name:\", file_name)\n",
    "print(\"file_type:\", file_type)\n",
    "print(\"dlm:\", dlm)\n",
    "print(\"chunk_size:\", chunk_size)\n",
    "print(\"overlap:\", overlap)\n",
    "######################################\n",
    "print(\"embed_model:\", embed_model)\n",
    "print(\"gen_model:\", gen_model)\n",
    "print(\"collection:\", collection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78c089f-3cb4-4260-97d1-cae74bc562d5",
   "metadata": {},
   "source": [
    "## delete collection for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe7a41f7-7fdc-404e-8d5b-8c9c1bb6cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Utility.registerClient()\n",
    "# if collection in client.collections.list_all():\n",
    "#     client.collections.delete(collection)\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc08db39-d5dd-411b-baac-9c033e9151cd",
   "metadata": {},
   "source": [
    "## Download module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99ce8c79-a2a9-4a1d-810a-a99a8ab705c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import weaviate\n",
    "import pdfplumber\n",
    "from weaviate.classes.config import Configure\n",
    "from datetime import datetime\n",
    "from weaviate.classes.config import Property, DataType\n",
    "import io\n",
    "import pandas as pd\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa07b18-c0ec-432a-b74e-32c52298ab8d",
   "metadata": {},
   "source": [
    "## Define Fucntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f808546-d254-4dd4-b708-6337eb78ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://host.docker.internal:11434\"\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs): # result in long text type str\n",
    "    # return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    return RunnableLambda(lambda _: \"\\n\".join(doc for doc in docs))\n",
    "    \n",
    "def createCollection(client):\n",
    "    # if present\n",
    "    if collection in client.collections.list_all():\n",
    "        return client.collections.get(collection)\n",
    "\n",
    "    # if not\n",
    "    return client.collections.create(\n",
    "        name=collection,\n",
    "        vectorizer_config=Configure.Vectorizer.text2vec_ollama(\n",
    "            api_endpoint=OLLAMA_API,\n",
    "            model=embed_model\n",
    "        ),\n",
    "        generative_config=Configure.Generative.ollama(\n",
    "            api_endpoint=OLLAMA_API,\n",
    "            model=gen_model\n",
    "        ),\n",
    "        properties=[\n",
    "            Property(name=\"title\", data_type=DataType.TEXT),\n",
    "            Property(name=\"content\", data_type=DataType.TEXT),\n",
    "            Property(name=\"source_type\", data_type=DataType.TEXT),\n",
    "            Property(name=\"source_id\", data_type=DataType.TEXT),\n",
    "            Property(name=\"index\", data_type=DataType.INT),\n",
    "            Property(name=\"timestamp\", data_type=DataType.DATE)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def chunkText(text, chunk_size, overlap):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "def ingestFileToWeaviate(bucket_name, path_to_file, title, chunk_size, overlap):\n",
    "    client = Utility.registerClient()\n",
    "\n",
    "    kb = createCollection(client)\n",
    "    \n",
    "    # Get file as bytes in memory from MinIO\n",
    "    file_bytes = Utility.readFileFromMinio(bucket_name, path_to_file)\n",
    "\n",
    "    # Define as one document\n",
    "    title = title\n",
    "    source_id = str(uuid.uuid4())\n",
    "    timestamp = datetime.utcnow().replace(microsecond=0).isoformat() + \"Z\"\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Answer the question based only on the context.\n",
    "        Context:{context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Answer:\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # LLM\n",
    "    llm = OllamaLLM(\n",
    "        model=\"deepseek-r1:7b\",\n",
    "        temperature=0,\n",
    "        base_url=\"http://host.docker.internal:11434\" \n",
    "    )\n",
    "        \n",
    "    if file_type == 'pdf':\n",
    "        with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:\n",
    "            texts = [page.extract_text() for page in pdf.pages]\n",
    "            ## Representation Summary\n",
    "            rag_chain = (\n",
    "                {\"context\": format_docs(texts), \"question\": RunnablePassthrough()}\n",
    "                | prompt\n",
    "                | llm\n",
    "                | StrOutputParser()\n",
    "            )\n",
    "            # generate summary\n",
    "            result = rag_chain.invoke(\"Summary this document for futher retrieval purpose, Only give the summary without explanation or extra reasoning\")\n",
    "            result = result.split('</think>')[-1]\n",
    "            kb.data.insert({\n",
    "                \"title\": title,\n",
    "                \"content\": result,\n",
    "                \"source_type\": \"summary\",\n",
    "                \"source_id\": source_id,\n",
    "                \"index\": 0,\n",
    "                \"timestamp\": timestamp\n",
    "            })\n",
    "            \n",
    "            \n",
    "            ## Data in Retrieve\n",
    "            for page in pdf.pages:\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    chunks = chunkText(text, chunk_size, overlap)\n",
    "                    index = 0\n",
    "                    for chunk in chunks:\n",
    "                        kb.data.insert({\n",
    "                            \"title\": title,\n",
    "                            \"content\": chunk,\n",
    "                            \"source_type\": file_type,\n",
    "                            \"source_id\": source_id,\n",
    "                            \"index\": index,\n",
    "                            \"timestamp\": timestamp\n",
    "                        })\n",
    "                        index += 1\n",
    "                        \n",
    "    elif file_type == 'txt' or file_type == 'csv':\n",
    "        file_bytes = Utility.readFileFromMinio(bucket_name, path_to_file)\n",
    "        df = pd.read_csv(io.StringIO(file_bytes.decode('utf-8')), on_bad_lines='skip')\n",
    "        texts = df.astype(str).apply(lambda row: \" | \".join(row), axis=1).tolist()\n",
    "        ## Representation Summary\n",
    "        rag_chain = (\n",
    "            {\"context\": format_docs(texts), \"question\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        # generate summary\n",
    "        result = rag_chain.invoke(\"Summary this document for futher retrieval purpose, Only give the summary without explanation or extra reasoning\")\n",
    "        result = result.split('</think>')[-1]\n",
    "        kb.data.insert({\n",
    "            \"title\": title,\n",
    "            \"content\": result,\n",
    "            \"source_type\": \"summary\",\n",
    "            \"source_id\": source_id,\n",
    "            \"index\": 0,\n",
    "            \"timestamp\": timestamp\n",
    "        })\n",
    "        \n",
    "        index = 0\n",
    "        for text in texts:\n",
    "            kb.data.insert({\n",
    "                \"title\": title,\n",
    "                \"content\": text,\n",
    "                \"source_type\": file_type,\n",
    "                \"source_id\": source_id,\n",
    "                \"index\": index,\n",
    "                \"timestamp\": timestamp\n",
    "            })\n",
    "            index += 1\n",
    "    \n",
    "    \n",
    "\n",
    "    client.close()\n",
    "    print(f\"Ingested {index} chunks from '{title}'\")\n",
    "    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa9c886-fdb3-4b9c-844f-412738b9e419",
   "metadata": {},
   "source": [
    "## Ingest data into vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6e717d1e-4776-4e98-aef5-1a094488c9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingested 944 chunks from 'BRID_data.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_143/2275134521.py:1: ResourceWarning: unclosed <socket.socket fd=66, family=2, type=1, proto=6, laddr=('172.18.0.7', 58982), raddr=('192.168.65.254', 11434)>\n",
      "  ingestFileToWeaviate(bucket_name, path_to_file+'/'+file_name, file_name, chunk_size, overlap)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "ingestFileToWeaviate(bucket_name, path_to_file+'/'+file_name, file_name, chunk_size, overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200bcd3c-6ab8-4742-97d3-2a6318874efc",
   "metadata": {},
   "source": [
    "## Observe collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e1e70407-9c75-4627-ad53-e95100bc6774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Bridknowledge\n",
      "\n",
      "\n",
      " break line here\n"
     ]
    }
   ],
   "source": [
    "# client = Utility.registerClient()\n",
    "# for i in client.collections.list_all():\n",
    "#     # print(client.collections.get(i))\n",
    "#     print(\"##################################################\")\n",
    "#     print(i)\n",
    "#     print(\"\\n\\n break line here\")\n",
    "# # client.collections.delete(\"Question\")\n",
    "# # client.collections.delete(\"Csvbrid\")\n",
    "\n",
    "                \n",
    "# client.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fe2464-0c76-46db-826a-30a28515082b",
   "metadata": {},
   "source": [
    "## query from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "01103be7-e5fa-48a2-83ec-33857710273f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"BRID_data.txt\",\n",
      "  \"source_id\": \"03df5026-748d-49da-a66d-437dcc1a31fd\",\n",
      "  \"index\": 5,\n",
      "  \"content\": \"6\\tPIJE\\t9.652\\t143.799883\\t105.20826\",\n",
      "  \"timestamp\": \"2025-04-09T15:28:02+00:00\",\n",
      "  \"source_type\": \"txt\"\n",
      "}\n",
      "17.68316650390625\n",
      "content : 6\tPIJE\t9.652\t143.799883\t105.20826\n",
      "#############################################\n"
     ]
    }
   ],
   "source": [
    "# import weaviate\n",
    "# import json\n",
    "# from datetime import datetime\n",
    "# from weaviate.classes.query import MetadataQuery, Filter\n",
    "\n",
    "# def serialize(obj):\n",
    "#     \"\"\"Helper function to handle serialization of datetime objects.\"\"\"\n",
    "#     if isinstance(obj, datetime):\n",
    "#         return obj.isoformat()  # Convert datetime to string in ISO format\n",
    "#     raise TypeError(\"Type not serializable\")\n",
    "\n",
    "# client = Utility.registerClient()\n",
    "\n",
    "# retriever = client.collections.get(collection)\n",
    "\n",
    "# # Perform the text generation\n",
    "# # Each query must target one collection at a time\n",
    "\n",
    "# # retriever.query.where(Filter.by_property(\"source_type\").equal(\"summary\"))\n",
    "# response = retriever.query.bm25( # search without model\n",
    "#     # query=\"Conclusion\",\n",
    "#     query = \"give me a record that Spp = PIJE, DBH = 9.652 and x-y coord are (143.799883, 105.20826)\",\n",
    "#     limit=1,\n",
    "#     query_properties=[\"content\"],\n",
    "#     return_metadata=MetadataQuery(score=True),\n",
    "# )\n",
    "\n",
    "# for obj in response.objects:\n",
    "#     print(json.dumps(obj.properties, default=serialize, indent=2))\n",
    "#     print(json.dumps(obj.metadata.score, default=serialize, indent=2))\n",
    "#     print(f\"content : {obj.properties['content']}\")\n",
    "#     print(\"#############################################\")\n",
    "\n",
    "# client.close()  # Free up resources\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
