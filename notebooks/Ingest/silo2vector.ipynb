{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4b38df5f-3f37-41af-9ca4-9281c59382ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# paramter cell do not remove!!\n",
    "# nb_parm='datalake|raw/pdf|Birddiversityanddistribution|pdf||300|150'\n",
    "nb_parm='datalake|raw/text-csv|PFW_spp_translation_table_May2024|csv||300|150'\n",
    "question = 'describe the characteristic of the brid from the follow context'\n",
    "embed_model = \"mxbai-embed-large\" \n",
    "gen_model = \"deepseek-r1:7b\"\n",
    "collection = \"Bridcsvknowledge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf819a96-44a2-4ff8-855e-7a7aab695c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"/home/jovyan/notebooks\")\n",
    "from Framework.module import Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "106e1347-3219-4752-a58a-b25c24773548",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do the task After this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "357bb00d-abbb-49b6-9688-2e5c2d7f371c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket_name: datalake\n",
      "path_to_file: raw/text-csv\n",
      "file_name: PFW_spp_translation_table_May2024.csv\n",
      "file_type: csv\n",
      "dlm: \n",
      "chunk_size: 300\n",
      "overlap: 150\n",
      "question: describe the characteristic of the brid from the follow context\n",
      "embed_model: mxbai-embed-large\n",
      "gen_model: deepseek-r1:7b\n",
      "collection: csvbrid\n"
     ]
    }
   ],
   "source": [
    "bucket_name, path_to_file, file_name, file_type, dlm, chunk_size, overlap = nb_parm.split('|')\n",
    "######PREPROCESSING###################\n",
    "file_name = file_name + '.' + file_type\n",
    "chunk_size = int(chunk_size)\n",
    "overlap = int(overlap)\n",
    "######################################\n",
    "print(\"bucket_name:\", bucket_name)\n",
    "print(\"path_to_file:\", path_to_file)\n",
    "print(\"file_name:\", file_name)\n",
    "print(\"file_type:\", file_type)\n",
    "print(\"dlm:\", dlm)\n",
    "print(\"chunk_size:\", chunk_size)\n",
    "print(\"overlap:\", overlap)\n",
    "######################################\n",
    "print(\"question:\", question)\n",
    "print(\"embed_model:\", embed_model)\n",
    "print(\"gen_model:\", gen_model)\n",
    "print(\"collection:\", collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fe7a41f7-7fdc-404e-8d5b-8c9c1bb6cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Utility.registerClient()\n",
    "if collection in client.collections.list_all():\n",
    "    client.collections.delete(collection)\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5f808546-d254-4dd4-b708-6337eb78ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import weaviate\n",
    "import pdfplumber\n",
    "from weaviate.classes.config import Configure\n",
    "from datetime import datetime\n",
    "from weaviate.classes.config import Property, DataType\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "OLLAMA_API = \"http://host.docker.internal:11434\"\n",
    "\n",
    "def createCollection(client):\n",
    "    # if present\n",
    "    if collection in client.collections.list_all():\n",
    "        return client.collections.get(collection)\n",
    "\n",
    "    # if not\n",
    "    return client.collections.create(\n",
    "        name=collection,\n",
    "        vectorizer_config=Configure.Vectorizer.text2vec_ollama(\n",
    "            api_endpoint=OLLAMA_API,\n",
    "            model=embed_model\n",
    "        ),\n",
    "        generative_config=Configure.Generative.ollama(\n",
    "            api_endpoint=OLLAMA_API,\n",
    "            model=gen_model\n",
    "        ),\n",
    "        properties=[\n",
    "            Property(name=\"title\", data_type=DataType.TEXT),\n",
    "            Property(name=\"content\", data_type=DataType.TEXT),\n",
    "            Property(name=\"source_type\", data_type=DataType.TEXT),\n",
    "            Property(name=\"source_id\", data_type=DataType.TEXT),\n",
    "            Property(name=\"index\", data_type=DataType.INT),\n",
    "            Property(name=\"timestamp\", data_type=DataType.DATE)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def chunkText(text, chunk_size, overlap):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "def ingestFileToWeaviate(bucket_name, path_to_file, title, chunk_size, overlap):\n",
    "    client = Utility.registerClient()\n",
    "\n",
    "    kb = createCollection(client)\n",
    "    \n",
    "    # Get PDF file as bytes from MinIO\n",
    "    file_bytes = Utility.readFileFromMinio(bucket_name, path_to_file)\n",
    "\n",
    "    # Define as one document\n",
    "    title = title\n",
    "    source_id = str(uuid.uuid4())\n",
    "    timestamp = datetime.utcnow().replace(microsecond=0).isoformat() + \"Z\"\n",
    "    \n",
    "    if file_type == 'pdf':\n",
    "        with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    chunks = chunkText(text, chunk_size, overlap)\n",
    "                    chunk_index = 0\n",
    "                    for chunk in chunks:\n",
    "                        kb.data.insert({\n",
    "                            \"title\": title,\n",
    "                            \"content\": chunk,\n",
    "                            \"source_type\": file_type,\n",
    "                            \"source_id\": source_id,\n",
    "                            \"index\": chunk_index,\n",
    "                            \"timestamp\": timestamp\n",
    "                        })\n",
    "                        chunk_index += 1\n",
    "        print(f\"Ingested {chunk_index} chunks from '{title}'\")\n",
    "                        \n",
    "    elif file_type == 'txt' or file_type == 'csv':\n",
    "        file_bytes = Utility.readFileFromMinio(bucket_name, path_to_file)\n",
    "        df = pd.read_csv(io.StringIO(file_bytes.decode('utf-8')), on_bad_lines='skip')\n",
    "        texts = df.astype(str).apply(lambda row: \" | \".join(row), axis=1).tolist()\n",
    "        text_index = 0\n",
    "        for text in texts:\n",
    "            kb.data.insert({\n",
    "                \"title\": title,\n",
    "                \"content\": text,\n",
    "                \"source_type\": file_type,\n",
    "                \"source_id\": source_id,\n",
    "                \"index\": text_index,\n",
    "                \"timestamp\": timestamp\n",
    "            })\n",
    "            text_index += 1\n",
    "        print(f\"Ingested {text_index} chunks from '{title}'\")\n",
    "\n",
    "    client.close()\n",
    "    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e717d1e-4776-4e98-aef5-1a094488c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingestFileToWeaviate(bucket_name, path_to_file+'/'+file_name, file_name, chunk_size, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e1e70407-9c75-4627-ad53-e95100bc6774",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Utility.registerClient()\n",
    "for i in client.collections.list_all():\n",
    "    print(client.collections.get(i))\n",
    "    print(\"##################################################\")\n",
    "    print(i)\n",
    "    print(\"\\n\\n break line here\")\n",
    "# client.collections.delete(\"Question\")\n",
    "# client.collections.delete(\"Csvbrid\")\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01103be7-e5fa-48a2-83ec-33857710273f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"PFW_spp_translation_table_May2024.csv\",\n",
      "  \"source_id\": \"a397302f-df85-4ae7-9202-5ec3879f2f67\",\n",
      "  \"index\": 1056,\n",
      "  \"content\": \"paired | nan | 15 | Myioborus pictus | Painted Redstart | 2023 | 33810\",\n",
      "  \"timestamp\": \"2025-04-09T06:19:40+00:00\",\n",
      "  \"source_type\": \"csv\"\n",
      "}\n",
      "5.711155891418457\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "import json\n",
    "from datetime import datetime\n",
    "from weaviate.classes.query import MetadataQuery, Filter\n",
    "\n",
    "def serialize(obj):\n",
    "    \"\"\"Helper function to handle serialization of datetime objects.\"\"\"\n",
    "    if isinstance(obj, datetime):\n",
    "        return obj.isoformat()  # Convert datetime to string in ISO format\n",
    "    raise TypeError(\"Type not serializable\")\n",
    "\n",
    "client = Utility.registerClient()\n",
    "\n",
    "questions = client.collections.get(collection)\n",
    "\n",
    "# Perform the text generation\n",
    "# Each query must target one collection at a time\n",
    "response = questions.query.bm25(\n",
    "    query=\"Myioborus pictus\",\n",
    "    limit=1,\n",
    "    query_properties=[\"content\"],\n",
    "    return_metadata=MetadataQuery(score=True),\n",
    ")\n",
    "\n",
    "for obj in response.objects:\n",
    "    print(json.dumps(obj.properties, default=serialize, indent=2))\n",
    "    print(json.dumps(obj.metadata.score, default=serialize, indent=2))\n",
    "\n",
    "\n",
    "client.close()  # Free up resources\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
