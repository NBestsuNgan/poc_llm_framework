{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "264672e2",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [7]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d827a92-d03c-4e5e-8dbd-92bd9f7f5129",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-04-09T03:00:03.348799Z",
     "iopub.status.busy": "2025-04-09T03:00:03.347737Z",
     "iopub.status.idle": "2025-04-09T03:00:03.365352Z",
     "shell.execute_reply": "2025-04-09T03:00:03.363304Z"
    },
    "papermill": {
     "duration": 0.045848,
     "end_time": "2025-04-09T03:00:03.368907",
     "exception": false,
     "start_time": "2025-04-09T03:00:03.323059",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# paramter cell do not remove!!\n",
    "nb_parm=''\n",
    "question = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e731d1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:00:03.439615Z",
     "iopub.status.busy": "2025-04-09T03:00:03.439086Z",
     "iopub.status.idle": "2025-04-09T03:00:03.450144Z",
     "shell.execute_reply": "2025-04-09T03:00:03.447128Z"
    },
    "papermill": {
     "duration": 0.059821,
     "end_time": "2025-04-09T03:00:03.455246",
     "exception": false,
     "start_time": "2025-04-09T03:00:03.395425",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nb_parm = \"bridnok\"\n",
    "question = \"describe the characteristic of the brid from the follow context\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "575c082c-c36d-49c2-a58f-f477e2635af3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:00:03.523751Z",
     "iopub.status.busy": "2025-04-09T03:00:03.523162Z",
     "iopub.status.idle": "2025-04-09T03:00:04.505793Z",
     "shell.execute_reply": "2025-04-09T03:00:04.504787Z"
    },
    "papermill": {
     "duration": 1.024403,
     "end_time": "2025-04-09T03:00:04.508698",
     "exception": false,
     "start_time": "2025-04-09T03:00:03.484295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"/home/jovyan/notebooks\")\n",
    "from Framework.module import Utility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3948dd-3761-4bdd-b62c-e8eb094ea50b",
   "metadata": {
    "papermill": {
     "duration": 0.039458,
     "end_time": "2025-04-09T03:00:04.564168",
     "exception": false,
     "start_time": "2025-04-09T03:00:04.524710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Do the task After this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c6d7aea-d442-400e-9dd3-104a3c7597f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:00:04.640877Z",
     "iopub.status.busy": "2025-04-09T03:00:04.640185Z",
     "iopub.status.idle": "2025-04-09T03:00:14.647531Z",
     "shell.execute_reply": "2025-04-09T03:00:14.645663Z"
    },
    "papermill": {
     "duration": 10.05003,
     "end_time": "2025-04-09T03:00:14.650760",
     "exception": false,
     "start_time": "2025-04-09T03:00:04.600730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb50f66b-425e-4436-a0e1-622dd2a1a8e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:00:14.725572Z",
     "iopub.status.busy": "2025-04-09T03:00:14.724847Z",
     "iopub.status.idle": "2025-04-09T03:00:14.748467Z",
     "shell.execute_reply": "2025-04-09T03:00:14.745266Z"
    },
    "papermill": {
     "duration": 0.080213,
     "end_time": "2025-04-09T03:00:14.752459",
     "exception": false,
     "start_time": "2025-04-09T03:00:14.672246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSince Ollama and Jupyter Notebook run in separate containers, \\nJupyter needs to communicate with Ollama via HTTP requests, \\nbecause they are not in the same process or environment.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Since Ollama and Jupyter Notebook run in separate containers, \n",
    "Jupyter needs to communicate with Ollama via HTTP requests, \n",
    "because they are not in the same process or environment.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1910727-4204-4506-b629-83412dbf89ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:00:14.799485Z",
     "iopub.status.busy": "2025-04-09T03:00:14.798534Z",
     "iopub.status.idle": "2025-04-09T03:01:02.486395Z",
     "shell.execute_reply": "2025-04-09T03:01:02.481944Z"
    },
    "papermill": {
     "duration": 47.756663,
     "end_time": "2025-04-09T03:01:02.528181",
     "exception": false,
     "start_time": "2025-04-09T03:00:14.771518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "The capital of Thailand is Bangkok.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# Explicitly define Ollama's API base URL\n",
    "llm = OllamaLLM(\n",
    "    model=\"deepseek-r1:7b\",\n",
    "    temperature=0,\n",
    "    # base_url=\"http://ollama:11434\"\n",
    "    base_url=\"http://host.docker.internal:11434\" # need to refer because it run as separate container the langchain not know what the end point of model are so this is need to be attached\n",
    "\n",
    ")\n",
    "\n",
    "# Define a simple question prompt\n",
    "question = \"What is the capital of thailand?\"\n",
    "response = llm.invoke(question)\n",
    "\n",
    "# Print the response\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5461bdd",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1f1a94a-9031-4b63-b57c-f5f44712c9c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:01:02.682039Z",
     "iopub.status.busy": "2025-04-09T03:01:02.681055Z",
     "iopub.status.idle": "2025-04-09T03:01:03.051512Z",
     "shell.execute_reply": "2025-04-09T03:01:03.050174Z"
    },
    "papermill": {
     "duration": 0.411335,
     "end_time": "2025-04-09T03:01:03.053143",
     "exception": true,
     "start_time": "2025-04-09T03:01:02.641808",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Delete the collection\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mcollections\u001b[38;5;241m.\u001b[39mdelete(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "# Delete the collection\n",
    "client.collections.delete(\"Question\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d83b86-ee99-4219-bd00-2be6c76f0248",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.config import Configure\n",
    "\n",
    "client = weaviate.connect_to_custom(\n",
    "    http_host=\"host.docker.internal\",\n",
    "    http_port=8081,\n",
    "    http_secure=False,  # Set to True if using HTTPS\n",
    "    grpc_host=\"host.docker.internal\",\n",
    "    grpc_port=50051,\n",
    "    grpc_secure=False,  # Set to True if using a secure gRPC connection\n",
    ")\n",
    "\n",
    "print(client.is_ready())  # Should return True if the connection is successful\n",
    "\n",
    "questions = client.collections.create(\n",
    "    name=\"Question\",\n",
    "    vectorizer_config = Configure.Vectorizer.text2vec_ollama(\n",
    "    api_endpoint=\"http://host.docker.internal:11434\",  # Ensures Weaviate inside Docker can talk to Ollama on host\n",
    "    model=\"mxbai-embed-large\"                          # The Ollama model name for embedding nomic-embed-text, mxbai-embed-large\n",
    "    ),\n",
    "    generative_config=Configure.Generative.ollama(              # Configure the Ollama generative integration\n",
    "        api_endpoint=\"http://host.docker.internal:11434\",       # Allow Weaviate from within a Docker container to contact your Ollama instance\n",
    "        model=\"deepseek-r1:7b\",                                       # The model to use\n",
    "    )\n",
    ")\n",
    "\n",
    "client.close()  # Free up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf6df07-57d2-47f8-8f5f-2dd572b31439",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import requests, json\n",
    "\n",
    "client = weaviate.connect_to_custom(\n",
    "    http_host=\"host.docker.internal\",\n",
    "    http_port=8081,\n",
    "    http_secure=False,  # Set to True if using HTTPS\n",
    "    grpc_host=\"host.docker.internal\",\n",
    "    grpc_port=50051,\n",
    "    grpc_secure=False,  # Set to True if using a secure gRPC connection\n",
    ")\n",
    "resp = requests.get(\n",
    "    \"https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json\"\n",
    ")\n",
    "data = json.loads(resp.text)\n",
    "\n",
    "questions = client.collections.get(\"Question\")\n",
    "\n",
    "with questions.batch.dynamic() as batch:\n",
    "    for d in data:\n",
    "        batch.add_object({\n",
    "            \"answer\": d[\"Answer\"],\n",
    "            \"question\": d[\"Question\"],\n",
    "            \"category\": d[\"Category\"],\n",
    "        })\n",
    "        if batch.number_errors > 10:\n",
    "            print(\"Batch import stopped due to excessive errors.\")\n",
    "            break\n",
    "\n",
    "failed_objects = questions.batch.failed_objects\n",
    "if failed_objects:\n",
    "    print(f\"Number of failed imports: {len(failed_objects)}\")\n",
    "    print(f\"First failed object: {failed_objects[0]}\")\n",
    "\n",
    "client.close()  # Free up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce9a906-8cee-4cb5-9374-ea5f44cc39cd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import json\n",
    "\n",
    "client = weaviate.connect_to_custom(\n",
    "    http_host=\"host.docker.internal\",\n",
    "    http_port=8081,\n",
    "    http_secure=False,  # Set to True if using HTTPS\n",
    "    grpc_host=\"host.docker.internal\",\n",
    "    grpc_port=50051,\n",
    "    grpc_secure=False,  # Set to True if using a secure gRPC connection\n",
    ")\n",
    "\n",
    "questions = client.collections.get(\"Question\")\n",
    "\n",
    "response = questions.query.near_text(\n",
    "    query=\"biology\",\n",
    "    limit=2\n",
    ")\n",
    "\n",
    "for obj in response.objects:\n",
    "    print(json.dumps(obj.properties, indent=2))\n",
    "\n",
    "client.close()  # Free up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7c9bea",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "#### INDEXING ####\n",
    "\n",
    "# Load Documents\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Embed\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OllamaEmbeddings(\n",
    "                                                model=\"mxbai-embed-large\",  # Or another embedding model, like `nomic-embed-text`\n",
    "                                                base_url=\"http://host.docker.internal:11434\"\n",
    "                                            )\n",
    "                                   )\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "#### RETRIEVAL and GENERATION ####\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = llm = OllamaLLM(\n",
    "    model=\"deepseek-r1:7b\",\n",
    "    temperature=0,\n",
    "    base_url=\"http://host.docker.internal:11434\" \n",
    ")\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Question\n",
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 61.919358,
   "end_time": "2025-04-09T03:01:04.021574",
   "environment_variables": {},
   "exception": true,
   "input_path": "/home/jovyan/notebooks/Ingest/testbrid.ipynb",
   "output_path": "/home/jovyan/notebooks/Log_output/Doc_bird/testbrid_executed.ipynb",
   "parameters": {
    "nb_parm": "bridnok",
    "question": "describe the characteristic of the brid from the follow context"
   },
   "start_time": "2025-04-09T03:00:02.102216",
   "version": "2.6.0"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}